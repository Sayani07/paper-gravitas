
@MISC{Healey2017-tv,
  title        = "Perception in Visualization",
  booktitle    = "{NC} State University Computer Science",
  author       = "Healey, Christopher G",
  month        =  oct,
  year         =  2017,
  howpublished = "\url{https://www.csc2.ncsu.edu/faculty/healey/PP/index.html}",
  note         = "Accessed: 2018-12-20",
  keywords     = "Literature Review Chapter 1;Literature Review Chapter
                  1/Criterion for bad/good plots;Literature Review 01Chapter
                  SG/Criterion for bad/good plots"
}

@INPROCEEDINGS{Van_Wijk_undated-nj,
  title     = "The Value of Visualization",
  booktitle = "{IEEE} Visualization 2005 - ({VIS'05})",
  author    = "van Wijk, J J",
  keywords  = "Literature Review Chapter 1;Literature Review Chapter
               1/Criterion for bad/good plots;Literature Review 01Chapter
               SG/Criterion for bad/good plots"
}

@ARTICLE{Wainer1984-co,
  title     = "How to Display Data Badly",
  author    = "Wainer, Howard",
  abstract  = "[Methods for displaying data badly have been developing for many
               years, and a wide variety of interesting and inventive schemes
               have emerged. Presented here is a synthesis yielding the 12 most
               powerful techniques that seem to underlie many of the
               realizations found in practice. These 12 (the dirty dozen) are
               identified and illustrated.]",
  journal   = "Am. Stat.",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.]",
  volume    =  38,
  number    =  2,
  pages     = "137--147",
  year      =  1984,
  keywords  = "Literature Review Chapter 1;Literature Review Chapter
               1/Criterion for bad/good plots;Literature Review 01Chapter
               SG/Criterion for bad/good plots"
}

@BOOK{Playfair2005-ew,
  title     = "Playfair's Commercial and Political Atlas and Statistical
               Breviary",
  author    = "Playfair, William",
  abstract  = "A scientific revolution began at the end of the 18th century
               with the creation and popularization of the graphic display of
               data by Scottish inventor William Playfair, who introduced the
               line graph, bar chart, and pie chart into statistics. His
               remarkable Atlas demonstrated how much could be learned if one
               plotted data graphically and looked for suggestive patterns to
               provide evidence for pursuing research. In the Statistical
               Breviary, Playfair invented the pie chart and expanded upon this
               concept to facilitate the comparison of the resources of
               European countries. Playfair's work has great relevance to
               contemporary science, but finding copies of his original
               versions is very difficult. This re-issuance of two of his
               classic works, with new explanatory material, allows access to
               his wisdom for the first time in two centuries. In full color
               exactly as Playfair hand-colored the original, this volume
               includes exact duplicates of the third edition of his classic
               Atlas as well as the Statistical Breviary. An additional feature
               is the inclusion of annotations and an extensive biography of
               the remarkable inventor. Howard Wainer is Distinquished Research
               Scientist at the National Board of Examiners and Adjunct
               Professor of Statistics at the Wharton School of the University
               of Pennsylvania. He has a Ph.D. in Psychometrics from Princeton
               University. Professor Wainer is the author of fifteen previous
               books, most recently, Graphic Discovery: A Trout in the Milk and
               Other Visual Adventures (2005).",
  publisher = "Cambridge University Press",
  year      =  2005,
  keywords  = "Literature Review 01Chapter SG/Criterion for bad/good plots",
  language  = "en"
}

@PHDTHESIS{Henkin2018-gs,
  title    = "A framework for hierarchical time-oriented data visualisation",
  author   = "Henkin, R",
  year     =  2018,
  school   = "City, University of London",
  keywords = "Literature Review 01Chapter SG/Time Granularities and
              Visualization"
}

@ARTICLE{Wickham_undated-vr,
  title    = "40 years of boxplots",
  author   = "Wickham, Hadley and Stryjewski, Lisa",
  keywords = "Boxplots;Literature Review 01Chapter SG/Time Granularities and
              Visualization"
}

@ARTICLE{Hyndman1996-ft,
  title     = "Computing and Graphing Highest Density Regions",
  author    = "Hyndman, Rob J",
  abstract  = "Many statistical methods involve summarizing a probability
               distribution by a region of the sample space covering a
               specified probability. One method of selecting such a region is
               to require it to contain points of relatively high density.
               Highest density regions are particularly useful for displaying
               multimodal distributions and, in such cases, may consist of
               several disjoint subsets-one for each local mode. In this paper,
               I propose a simple method for computing a highest density region
               from any given (possibly multivariate) density f(x) that is
               bounded and continuous in x. Several examples of the use of
               highest density regions in statistical graphics are also given.
               A new form of boxplot is proposed based on highest density
               regions; versions in one and two dimensions are given. Highest
               density regions in higher dimensions are also discussed and
               plotted.",
  journal   = "Am. Stat.",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.]",
  volume    =  50,
  number    =  2,
  pages     = "120--126",
  year      =  1996,
  keywords  = "Literature Review 01Chapter SG/Time Granularities and
               Visualization"
}

@book{aigner2011visualization,
  title={Visualization of time-oriented data},
  author={Aigner, Wolfgang and Miksch, Silvia and Schumann, Heidrun and Tominski, Christian},
  year={2011},
  publisher={Springer Science \& Business Media}
}


@ARTICLE{Cleveland1982-ag,
  title     = "Graphical Methods for Seasonal Adjustment",
  author    = "Cleveland, William S and Terpenning, Irma J",
  abstract  = "[Graphical displays deserve to be a routine part of seasonal
               adjustment, and their routine use is now feasible because of the
               current revolution in computer graphical hardware and software.
               We present and illustrate seven graphical displays that provide
               powerful tools for judging the adequacy of the seasonal
               adjustment of a series and for understanding the behavior of the
               trend, seasonal, and irregular components.]",
  journal   = "J. Am. Stat. Assoc.",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.]",
  volume    =  77,
  number    =  377,
  pages     = "52--62",
  year      =  1982,
  keywords  = "Literature Review 01Chapter SG/Time Granularities and
               Visualization"
}

@BOOK{Wills2011-yv,
  title     = "Visualizing Time: Designing Graphical Representations for
               Statistical Data",
  author    = "Wills, Graham",
  abstract  = "Art, or Science? Which of these is the right way to think of the
               field of visualization? This is not an easy question to answer,
               even for those who have many years experience in making
               graphical depictions of data with a view to help people
               understand it and take action. In this book, Graham Wills
               bridges the gap between the art and the science of visually
               representing data. He does not simply give rules and advice, but
               bases these on general principles and provide a clear path
               between them This book is concerned with the graphical
               representation of time data and is written to cover a range of
               different users. A visualization expert designing tools for
               displaying time will find it valuable, but so also should a
               financier assembling a report in a spreadsheet, or a medical
               researcher trying to display gene sequences using a commercial
               statistical package.",
  publisher = "Springer",
  month     =  dec,
  year      =  2011,
  keywords  = "Literature Review 01Chapter SG/Time Granularities and
               Visualization",
  language  = "en"
}

@INPROCEEDINGS{Van_Wijk1999-um,
  title     = "Cluster and calendar based visualization of time series data",
  booktitle = "Proceedings 1999 {IEEE} Symposium on Information Visualization
               ({InfoVis'99})",
  author    = "Van Wijk, J J and Van Selow, E R",
  abstract  = "A new method is presented to get an insight into univariate time
               series data. The problem addressed is how to identify patterns
               and trends on multiple time scales (days, weeks, seasons)
               simultaneously. The solution presented is to cluster similar
               daily data patterns, and to visualize the average patterns as
               graphs and the corresponding days on a calendar. This
               presentation provides a quick insight into both standard and
               exceptional patterns. Furthermore, it is well suited to
               interactive exploration. Two applications, numbers of employees
               present and energy consumption, are presented.",
  pages     = "4--9",
  month     =  oct,
  year      =  1999,
  keywords  = "data visualisation;time series;pattern
               recognition;graphs;cluster based visualization;calendar based
               visualization;univariate time series data;pattern
               clustering;graphs;employees;energy consumption;Calendars;Data
               visualization;Time series analysis;Energy consumption;Time
               measurement;Data analysis;Fourier transforms;Mathematics;Pattern
               analysis;Data mining;Literature Review 01Chapter SG/Time
               Granularities and Visualization"
}

@BOOK{Hyndman2018-ev,
  title     = "Forecasting: principles and practice",
  author    = "Hyndman, Rob J and Athanasopoulos, George",
  abstract  = "Forecasting is required in many situations. Stocking an
               inventory may require forecasts of demand months in advance.
               Telecommunication routing requires traffic forecasts a few
               minutes ahead. Whatever the circumstances or time horizons
               involved, forecasting is an important aid in effective and
               efficient planning.This textbook provides a comprehensive
               introduction to forecasting methods and presents enough
               information about each method for readers to use them sensibly.",
  publisher = "OTexts",
  month     =  may,
  year      =  2018,
  keywords  = "Literature Review 01Chapter SG/Time Granularities and
               Visualization",
  language  = "en"
}

@INCOLLECTION{Bettini1998-ed,
  title     = "A glossary of time granularity concepts",
  booktitle = "Temporal Databases: Research and Practice",
  author    = "Bettini, Claudio and Dyreson, Curtis E and Evans, William S and
               Snodgrass, Richard T and Wang, X Sean",
  editor    = "Etzion, Opher and Jajodia, Sushil and Sripada, Suryanarayana",
  publisher = "Springer Berlin Heidelberg",
  pages     = "406--413",
  year      =  1998,
  address   = "Berlin, Heidelberg",
  keywords  = "Literature Review 01Chapter SG/Time Granularities and
               Visualization"
}

@INCOLLECTION{Jensen1998-qn,
  title     = "The consensus glossary of temporal database concepts ---
               February 1998 version",
  booktitle = "Temporal Databases: Research and Practice",
  author    = "Jensen, Christian S and Dyreson, Curtis E and B{\"o}hlen,
               Michael and Clifford, James and Elmasri, Ramez and Gadia, Shashi
               K and Grandi, Fabio and Hayes, Pat and Jajodia, Sushil and
               K{\"A}fer, Wolfgang and Kline, Nick and Lorentzos, Nikos and
               Mitsopoulos, Yannis and Montanari, Angelo and Nonen, Daniel and
               Peressi, Elisa and Pernici, Barbara and Roddick, John F and
               Sarda, Nandlal L and Scalas, Maria Rita and Segev, Arie and
               Snodgrass, Richard T and Soo, Mike D and Tansel, Abdullah and
               Tiberio, Paolo and Wiederhold, Gio",
  editor    = "Etzion, Opher and Jajodia, Sushil and Sripada, Suryanarayana",
  abstract  = "This document1 contains definitions of a wide range of concepts
               specific to and widely used within temporal databases. In
               addition to providing definitions, the document also includes
               explanations of concepts as well as discussions of the adopted
               names.",
  publisher = "Springer Berlin Heidelberg",
  pages     = "367--405",
  year      =  1998,
  address   = "Berlin, Heidelberg",
  keywords  = "Literature Review 01Chapter SG/Time Granularities and
               Visualization"
}

@ARTICLE{Mcgill1978-hg,
  title     = "Variations of Box Plots",
  author    = "Mcgill, Robert and Tukey, John W and Larsen, Wayne A",
  abstract  = "Abstract Box plots display batches of data. Five values from a
               set of data are conventionally used; the extremes, the upper and
               lower hinges (quartiles), and the median. Such plots are
               becoming a widely used tool in exploratory data analysis and in
               preparing visual summaries for statisticians and
               nonstatisticians alike. Three variants of the basic display,
               devised by the authors, are described. The first visually
               incorporates a measure of group size; the second incorporates an
               indication of rough significance of differences between medians;
               the third combines the features of the first two. These
               techniques are displayed by examples.",
  journal   = "Am. Stat.",
  publisher = "Taylor \& Francis",
  volume    =  32,
  number    =  1,
  pages     = "12--16",
  month     =  feb,
  year      =  1978,
  keywords  = "Literature Review 01Chapter SG/Time Granularities and
               Visualization"
}

@ARTICLE{Hintze1998-zi,
  title     = "Violin Plots: A Box {Plot-Density} Trace Synergism",
  author    = "Hintze, Jerry L and Nelson, Ray D",
  abstract  = "[Many modifications build on Tukey's original box plot. A
               proposed further adaptation, the violin plot, pools the best
               statistical features of alternative graphical representations of
               batches of data. It adds the information available from local
               density estimates to the basic summary statistics inherent in
               box plots. This marriage of summary statistics and density shape
               into a single plot provides a useful tool for data analysis and
               exploration.]",
  journal   = "Am. Stat.",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.]",
  volume    =  52,
  number    =  2,
  pages     = "181--184",
  year      =  1998,
  keywords  = "Literature Review 01Chapter SG/Time Granularities and
               Visualization"
}

@ARTICLE{Potter2010-qc,
  title    = "Visualizing Summary Statistics and Uncertainty",
  author   = "Potter, K and Kniss, J and Riesenfeld, R and Johnson, C R",
  abstract = "Abstract The graphical depiction of uncertainty information is
              emerging as a problem of great importance. Scientific data sets
              are not considered complete without indications of error,
              accuracy, or levels of confidence. The visual portrayal of this
              information is a challenging task. This work takes inspiration
              from graphical data analysis to create visual representations
              that show not only the data value, but also important
              characteristics of the data including uncertainty. The canonical
              box plot is reexamined and a new hybrid summary plot is presented
              that incorporates a collection of descriptive statistics to
              highlight salient features of the data. Additionally, we present
              an extension of the summary plot to two dimensional
              distributions. Finally, a use-case of these new plots is
              presented, demonstrating their ability to present high-level
              overviews as well as detailed insight into the salient features
              of the underlying data distribution.",
  journal  = "Comput. Graph. Forum",
  volume   =  29,
  number   =  3,
  pages    = "823--832",
  month    =  aug,
  year     =  2010,
  keywords = "Literature Review 01Chapter SG/Time Granularities and
              Visualization"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@BOOK{Tukey1977-jx,
  title     = "Exploratory data analysis",
  author    = "Tukey, John W",
  abstract  = "We were together learning how to use the analysis of variance,
               and perhaps it is worth while stating an impression that I have
               formed-that the analysis of variance, which may perhaps be
               called a statistical method, because that term is a very
               ambiguous one---is not a mathematical theorem, but rather a
               convenient method of arranging the arithmetic. Just as in
               arithmetical textbooks---if we can recall their contents---we
               were given rules for arranging how to find the greatest common
               measure, and how to work out a sum in practice, and were âŠ",
  publisher = "Reading, Mass.",
  volume    =  2,
  year      =  1977,
  keywords  = "Literature Review 01Chapter SG/Time Granularities and
               Visualization"
}

@ARTICLE{Benjamini1988-io,
  title     = "Opening the Box of a Boxplot",
  author    = "Benjamini, Yoav",
  abstract  = "Abstract Variations of the boxplot are suggested, in which the
               sides of the box are used to convey information about the
               density of the values in a batch. The ease of computation by
               hand of the original boxplot had to be sacrificed, as the
               variations are computer-intensive. Still, the plots were
               implemented on a desktop personal computer (Apple Macintosh), in
               a way designed to keep their ease of computation by computer.
               The result is a dynamic display of densities and summaries.",
  journal   = "Am. Stat.",
  publisher = "Taylor \& Francis",
  volume    =  42,
  number    =  4,
  pages     = "257--262",
  month     =  nov,
  year      =  1988,
  keywords  = "Literature Review 01Chapter SG/Time Granularities and
               Visualization"
}

@ARTICLE{Hofmann2017-sg,
  title     = "{Letter-Value} Plots: Boxplots for Large Data",
  author    = "Hofmann, Heike and Wickham, Hadley and Kafadar, Karen",
  abstract  = "ABSTRACTBoxplots are useful displays that convey rough
               information about the distribution of a variable. Boxplots were
               designed to be drawn by hand and work best for small datasets,
               where detailed estimates of tail behavior beyond the quartiles
               may not be trustworthy. Larger datasets afford more precise
               estimates of tail behavior, but boxplots do not take advantage
               of this precision, instead presenting large numbers of extreme,
               though not unexpected, observations. Letter-value plots address
               this problem by including more detailed information about the
               tails using ?letter values,? an order statistic defined by
               Tukey. Boxplots display the first two letter values (the median
               and quartiles); letter-value plots display further letter values
               so far as they are reliable estimates of their corresponding
               quantiles. We illustrate letter-value plots with real data that
               demonstrate their usefulness for large datasets. All graphics
               are created using the R package lvplot, and code and data are
               available in the supplementary materials.",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "Taylor \& Francis",
  volume    =  26,
  number    =  3,
  pages     = "469--477",
  month     =  jul,
  year      =  2017,
  keywords  = "Boxplots;Literature Review 01Chapter SG/Time Granularities and
               Visualization"
}

@BOOK{Wilkinson1999-nk,
  title    = "The Grammar of Graphics",
  author   = "Wilkinson, Leland",
  year     =  1999,
  keywords = "Literature Review 01Chapter SG/Time Granularities and
              Visualization"
}

@Book{Wickham2009-pk,
   author = {Hadley Wickham},
   title = {ggplot2: Elegant Graphics for Data Analysis},
   publisher = {Springer-Verlag New York},
   year = {2016},
   isbn = {978-3-319-24277-4},
   url = {http://ggplot2.org},
 }

@ARTICLE{Brehmer2017-st,
  title    = "Timelines Revisited: A Design Space and Considerations for
              Expressive Storytelling",
  author   = "Brehmer, Matthew and Lee, Bongshin and Bach, Benjamin and Riche,
              Nathalie Henry and Munzner, Tamara",
  abstract = "There are many ways to visualize event sequences as timelines. In
              a storytelling context where the intent is to convey multiple
              narrative points, a richer set of timeline designs may be more
              appropriate than the narrow range that has been used for
              exploratory data analysis by the research community. Informed by
              a survey of 263 timelines, we present a design space for
              storytelling with timelines that balances expressiveness and
              effectiveness, identifying 14 design choices characterized by
              three dimensions: representation, scale, and layout. Twenty
              combinations of these choices are viable timeline designs that
              can be matched to different narrative points, while smooth
              animated transitions between narrative points allow for the
              presentation of a cohesive story, an important aspect of both
              interactive storytelling and data videos. We further validate
              this design space by realizing the full set of viable timeline
              designs and transitions in a proof-of-concept sandbox
              implementation that we used to produce seven example timeline
              stories. Ultimately, this work is intended to inform and inspire
              the design of future tools for storytelling with timelines.",
  journal  = "IEEE Trans. Vis. Comput. Graph.",
  volume   =  23,
  number   =  9,
  pages    = "2151--2164",
  month    =  sep,
  year     =  2017,
  keywords = "Literature Review Chapter 1;Literature Review Chapter 1/Dynamic
              Graph Visualization;Literature Review 01Chapter SG/Dynamic Graph
              Visualization",
  language = "en"
}

@ARTICLE{Fan_Du2017-xv,
  title    = "Coping with Volume and Variety in Temporal Event Sequences:
              Strategies for Sharpening Analytic Focus",
  author   = "{Fan Du} and Shneiderman, Ben and Plaisant, Catherine and Malik,
              Sana and Perer, Adam",
  abstract = "The growing volume and variety of data presents both
              opportunities and challenges for visual analytics. Addressing
              these challenges is needed for big data to provide valuable
              insights and novel solutions for business, security, social
              media, and healthcare. In the case of temporal event sequence
              analytics it is the number of events in the data and variety of
              temporal sequence patterns that challenges users of visual
              analytic tools. This paper describes 15 strategies for sharpening
              analytic focus that analysts can use to reduce the data volume
              and pattern variety. Four groups of strategies are proposed: (1)
              extraction strategies, (2) temporal folding, (3) pattern
              simplification strategies, and (4) iterative strategies. For each
              strategy, we provide examples of the use and impact of this
              strategy on volume and/or variety. Examples are selected from 20
              case studies gathered from either our own work, the literature,
              or based on email interviews with individuals who conducted the
              analyses and developers who observed analysts using the tools.
              Finally, we discuss how these strategies might be combined and
              report on the feedback from 10 senior event sequence analysts.",
  journal  = "IEEE Trans. Vis. Comput. Graph.",
  volume   =  23,
  number   =  6,
  pages    = "1636--1649",
  month    =  jun,
  year     =  2017,
  keywords = "Literature Review Chapter 1;Literature Review Chapter 1/Dynamic
              Graph Visualization;Literature Review 01Chapter SG/Dynamic Graph
              Visualization",
  language = "en"
}

@ARTICLE{Beck2017-em,
  title    = "A Taxonomy and Survey of Dynamic Graph Visualization",
  author   = "Beck, Fabian and Burch, Michael and Diehl, Stephan and Weiskopf,
              Daniel",
  abstract = "Abstract Dynamic graph visualization focuses on the challenge of
              representing the evolution of relationships between entities in
              readable, scalable and effective diagrams. This work surveys the
              growing number of approaches in this discipline. We derive a
              hierarchical taxonomy of techniques by systematically
              categorizing and tagging publications. While static graph
              visualizations are often divided into node-link and matrix
              representations, we identify the representation of time as the
              major distinguishing feature for dynamic graph visualizations:
              either graphs are represented as animated diagrams or as static
              charts based on a timeline. Evaluations of animated approaches
              focus on dynamic stability for preserving the viewer's mental map
              or, in general, compare animated diagrams to timeline-based ones.
              A bibliographic analysis provides insights into the organization
              and development of the field and its community. Finally, we
              identify and discuss challenges for future research. We also
              provide feedback from experts, collected with a questionnaire,
              which gives a broad perspective of these challenges and the
              current state of the field.",
  journal  = "Comput. Graph. Forum",
  volume   =  36,
  number   =  1,
  pages    = "133--159",
  month    =  jan,
  year     =  2017,
  keywords = "Literature Review Chapter 1;Literature Review Chapter 1/Dynamic
              Graph Visualization;Literature Review 01Chapter SG/Dynamic Graph
              Visualization"
}

@ARTICLE{Beck_undated-sc,
  title    = "The State of the Art in Visualizing Dynamic Graphs",
  author   = "Beck, Fabian and Burch, Michael and Diehl, Stephan and Weiskopf,
              Daniel",
  keywords = "Literature Review Chapter 1;Literature Review Chapter 1/Dynamic
              Graph Visualization;Literature Review 01Chapter SG/Dynamic Graph
              Visualization"
}


@Manual{Earo-Sugrrants,
  title = {sugrrants: Supporting Graphs for Analysing Time Series},
  author = {Earo Wang and Di Cook and Rob Hyndman},
  year = {2018},
  note = {R package version 0.1.5},
  url = {https://CRAN.R-project.org/package=sugrrants},
}


@book{hyndman2018forecasting,
  title={Forecasting: principles and practice},
  author={Hyndman, Rob J and Athanasopoulos, George},
  year={2018},
  publisher={OTexts}
}

@ARTICLE{Wainer1992-ml,
   title     = "Understanding Graphs and Tables",
   author    = "Wainer, Howard",
   abstract  = "Quantitative phenomena can be displayed effectively in a variety
                of ways, but to do so requires an understanding of both the
                structure of the phenomena and the limitations of candidate
                display formats. This article (a) re-counts three historic
                instances of the vital role data displays played in important
                discoveries, (b) provides three levels of information that form
                the basis of a theory of display to help us better measure both
                display quality and human graphicacy, and (c) describes three
                steps to improve the quality of tabular presentation.",
   journal   = "Educ. Res.",
   publisher = "American Educational Research Association",
   volume    =  21,
   number    =  1,
   pages     = "14--23",
   month     =  jan,
   year      =  1992
   }

   @BOOK{Unwin2016-aq,
    title     = "Graphical Data Analysis with {R}",
    author    = "Unwin, Antony",
    abstract  = "See How Graphics Reveal Information Graphical Data Analysis with
                 R shows you what information you can gain from graphical
                 displays. The book focuses on why you draw graphics to display
                 data and which graphics to draw (and uses R to do so). All the
                 datasets are available in R or one of its packages and the R
                 code is available at rosuda.org/GDA. Graphical data analysis is
                 useful for data cleaning, exploring data structure, detecting
                 outliers and unusual groups, identifying trends and clusters,
                 spotting local patterns, evaluating modelling output, and
                 presenting results. This book guides you in choosing graphics
                 and understanding what information you can glean from them. It
                 can be used as a primary text in a graphical data analysis
                 course or as a supplement in a statistics course. Colour
                 graphics are used throughout.",
    publisher = "CRC Press",
    month     =  apr,
    year      =  2016,
    language  = "en"
  }

  @BOOK{Cleveland1993-fn,
    title     = "Visualizing Data",
    author    = "Cleveland, William S",
    publisher = "Hobart Press",
    year      =  1993
  }


   @BOOK{Maimon2010-ac,
     title     = "Data Mining and Knowledge Discovery Handbook",
     author    = "Maimon, Oded and Rokach, Lior",
     abstract  = "Knowledge Discovery demonstrates intelligent computing at its
                  best, and is the most desirable and interesting end-product of
                  Information Technology. To be able to discover and to extract
                  knowledge from data is a task that many researchers and
                  practitioners are endeavoring to accomplish. There is a lot of
                  hidden knowledge waiting to be discovered -- this is the
                  challenge created by today's abundance of data. Data Mining and
                  Knowledge Discovery Handbook, 2nd Edition organizes the most
                  current concepts, theories, standards, methodologies, trends,
                  challenges and applications of data mining (DM) and knowledge
                  discovery in databases (KDD) into a coherent and unified
                  repository. This handbook first surveys, then provides
                  comprehensive yet concise algorithmic descriptions of methods,
                  including classic methods plus the extensions and novel methods
                  developed recently. This volume concludes with in-depth
                  descriptions of data mining applications in various
                  interdisciplinary industries including finance, marketing,
                  medicine, biology, engineering, telecommunications, software,
                  and security. Data Mining and Knowledge Discovery Handbook, 2nd
                  Edition is designed for research scientists, libraries and
                  advanced-level students in computer science and engineering as a
                  reference. This handbook is also suitable for professionals in
                  industry, for computing applications, information systems
                  management, and strategic research management.",
     publisher = "Springer Science \& Business Media",
     month     =  sep,
     year      =  2010,
     language  = "en"
   }

    @ARTICLE{Zhang2003-bj,
      title    = "Spatial Cone Tree: An Auxiliary Search Structure for
                  Correlation-based Similarity Queries on Spatial Time Series Data",
      author   = "Zhang, Pusheng and Shekhar, Shashi and Kumar, Vipin and Huang,
                  Yan",
      abstract = "ResearchGate is a network dedicated to science and research.
                  Connect, collaborate and discover scientific publications, jobs
                  and conferences. All for free.",
      month    =  nov,
      year     =  2003
    }

    @ARTICLE{Camossi2006-lg,
  title    = "A multigranular object-oriented framework supporting
              spatio-temporal granularity conversions",
  author   = "Camossi, Elena and Bertolotti, Mario and Bertino, Elisa",
  abstract = "Several application domains require handling spatio-temporal
              data. However, traditional Geographic Information Systems (GIS)
              and database models do not adequately support temporal aspects of
              spatial data. A crucial issue relates to the choice of the
              appropriate granularity. Unfortunately, while a formalisation of
              the concept of temporal granularity has been proposed and widely
              adopted, no consensus exists on the notion of spatial
              granularity. In this paper, we address these open problems, by
              proposing a formal definition of spatial granularity and by
              designing a spatio-temporal framework for the management of
              spatial and temporal information at different granularities. We
              present a spatio-temporal extension of the ODMG type system with
              specific types for defining multigranular spatio-temporal
              properties. Granularity conversion functions are introduced to
              obtain attributes values at different spatial and temporal
              granularities.",
  series   = "Cyber Center Publications",
  year     =  2006
}

@ARTICLE{Euzenat2005-de,
   title  = "Time Granularity",
   author = "Euzenat, Jerome and Montanari, Angelo",
   year   =  2005
 }
 
@ARTICLE{Grolemund2011-qf,
   title   = "Dates and times made easy with lubridate",
   author  = "Grolemund, Garrett and Wickham, Hadley and {Others}",
   journal = "J. Stat. Softw.",
   volume  =  40,
   number  =  3,
   pages   = "1--25",
   year    =  2011
 }
 
 @MANUAL{smart-meter,
  title       = {Smart-Grid Smart-City Customer Trial Data},
  author      = "{Department of the Environment and Energy}",
  institution = "Department of the Environment and Energy, Australia",
  year        =  2018,
  url         = "https://data.gov.au/dataset/4e21dea3-9b87-4610-94c7-15a8a77907ef",
  urldate     = {2018-11-19},
  address     = "Australian Government, Department of the Environment and Energy"
}


 @ARTICLE{Bettini2000-vy,
   title    = "Symbolic representation of user-defined time granularities",
   author   = "Bettini, Claudio and De Sibi, Roberto",
   abstract = "In the recent literature on time representation, an effort has
               been made to characterize the notion of time granularity and the
               relationships between granularities. The main goals are having a
               common framework for their specification, and allowing the
               interoperability of systems adopting different time
               granularities. This paper considers the mathematical
               characterization of finite and periodic time granularities, and
               investigates the requirements for a user-friendly symbolic
               formalism that could be used for their specification. Instead of
               proposing yet another formalism, the paper analyzes the
               expressiveness of known symbolic formalisms for the
               representation of granularities, using the mathematical
               characterization as a reference model. Based on this analysis, a
               significant extension to the collection formalism defined in [15]
               is proposed, in order to capture a practically interesting class
               of periodic granularities.",
   journal  = "Ann. Math. Artif. Intell.",
   volume   =  30,
   number   =  1,
   pages    = "53--92",
   month    =  jun,
   year     =  2000
 }
 
 @ARTICLE{Ning2002-tf,
   title    = "An Algebraic Representation of Calendars",
   author   = "Ning, Peng and Wang, Xiaoyang Sean and Jajodia, Sushil",
   abstract = "This paper uses an algebraic approach to define temporal
               granularities and calendars. All the granularities in a calendar
               are expressed as algebraic expressions based on a single
               ``bottom'' granularity. The operations used in the algebra
               directly reflect the ways with which people construct new
               granularities from existing ones, and hence yield more natural
               and compact granularities definitions. Calendar is formalized on
               the basis of the algebraic operations, and properties of
               calendars are studied. As a step towards practical applications,
               the paper also presents algorithms for granule conversions
               between granularities in a calendar.",
   journal  = "Ann. Math. Artif. Intell.",
   volume   =  36,
   number   =  1,
   pages    = "5--38",
   month    =  sep,
   year     =  2002
 }
 

 
@article{wang2019tsibble,
  Author = {Earo Wang and Dianne Cook and Rob J Hyndman},
  Title = {A new tidy data structure to support exploration and modeling of temporal data},
  journal = {Journal of Computational and Graphical Statistics},
  year = {2019},
  doi = {10.1080/10618600.2019.1695624}
}

@ARTICLE{G_Grolemund2011-vm,
   title   = "Dates and times made easy with lubridate",
   author  = "G Grolemund, H Wickham",
   journal = "Journal of Statistical Software",
   year    =  2011
 }
 
 
@BOOK{Wickham2009-pk,
   title  = "ggplot2: Elegant Graphics for Data Analysis",
   author = "Wickham, Hadley",
   year   =  2009
 }
 
 @ARTICLE{2012-la,
   title   = "Visualising Variations in Household Energy Consumption",
   author  = "{Goodwin, S And Dykes,}",
   journal = "IEEE Conference on Visual Analytics Science and Technology (VAST)",
   year    =  2012
 } 
  
  
@misc{wang2018calendar,
  Author = {Earo Wang and Dianne Cook and Rob J Hyndman},
  Title = {Calendar-based graphics for visualizing people's daily schedules},
  Year = {2018},
  Eprint = {arXiv:1810.09624},
}  



@BOOK{Reingold2001-kf,
   title     = "Calendrical Calculations Millennium Edition",
   author    = "Reingold, Edward M and Dershowitz, Nachum",
   abstract  = "This new edition of the successful calendars book is being
                published at the turn of the millennium and expands the
                treatment of the previous edition to new calendars and variants.
                As interest grows in the impact of seemingly arbitrary
                calendrical systems upon our daily lives, this book frames the
                world in a completely algorithmic form. The book gives a
                description of twenty-five calendars and how they relate to one
                another: the Gregorian (current civil), ISO (International
                Organization for Standardization), Egyptian (and nearly
                identical Armenian), Julian (old civil), Coptic, Ethiopic,
                Islamic (Moslem), modern Persian (both astronomical and
                arithmetic forms), Baha'i (both present and future forms),
                Hebrew (Jewish), Mayan (long count, haab, and tzolkin), Balinese
                Pawukon, French Revolutionary (both astronomical and arithmetic
                forms), Chinese (and nearly identical Japanese), old Hindu
                (solar and lunisolar), and modern Hindu (solar and lunisolar).
                Easy conversion among these calendars is a by-product of the
                approach, as is the determination of secular and religious
                holidays. Calendrical Calculations makes accurate calendrical
                algorithms readily available for computer use with LISP,
                Mathematica, and Java code for all the algorithms included on
                the CD, and updates are available on the Web. This book will be
                a valuable resource for working programmers as well as a fount
                of useful algorithmic tools for computer scientists. In
                addition, the lay reader will find the historical setting and
                general calendar descriptions of great interest.",
   publisher = "Cambridge University Press",
   month     =  aug,
   year      =  2001,
   language  = "en"
 }
 
@Manual{R-gravitas,
    title = {gravitas: Explore Probability Distributions for Bivariate Temporal
Granularities},
    author = {Sayani Gupta and Rob Hyndman and Di Cook and Antony Unwin},
    year = {2019},
    note = {R package version 0.1.0},
    url = {https://CRAN.R-project.org/package=gravitas},
  }
  
@Manual{R-dplyr,
  title = {dplyr: A Grammar of Data Manipulation},
  author = {Hadley Wickham and Romain François and Lionel Henry and Kirill Müller},
  year = {2019},
  note = {R package version 0.8.3},
  url = {https://CRAN.R-project.org/package=dplyr},
}


@Manual{R-magrittr,
  title = {magrittr: A Forward-Pipe Operator for R},
  author = {Stefan Milton Bache and Hadley Wickham},
  year = {2014},
  note = {R package version 1.5},
  url = {https://CRAN.R-project.org/package=magrittr},
}

@Manual{R-rlang,
  title = {rlang: Functions for Base Types and Core R and 'Tidyverse' Features},
  author = {Lionel Henry and Hadley Wickham},
  year = {2019},
  note = {R package version 0.4.0},
  url = {https://CRAN.R-project.org/package=rlang},
}

@Manual{R-tidyr,
  title = {tidyr: Tidy Messy Data},
  author = {Hadley Wickham and Lionel Henry},
  year = {2019},
  note = {http://tidyr.tidyverse.org, https://github.com/tidyverse/tidyr},
}
@Manual{R-tsibble,
  title = {tsibble: Tidy Temporal Data Frames and Tools},
  author = {Earo Wang and Di Cook and Rob Hyndman and Mitchell O'Hara-Wild},
  year = {2019},
  note = {R package version 0.8.3.9000},
  url = {https://tsibble.tidyverts.org},
}

@ARTICLE{Hyndman1996-ty,
   title     = "Sample Quantiles in Statistical Packages",
   author    = "Hyndman, Rob J and Fan, Yanan",
   abstract  = "Abstract There are a large number of different definitions used
                for sample quantiles in statistical computer packages. Often
                within the same package one definition will be used to compute a
                quantile explicitly, while other definitions may be used when
                producing a boxplot, a probability plot, or a QQ plot. We
                compare the most commonly implemented sample quantile
                definitions by writing them in a common notation and
                investigating their motivation and some of their properties. We
                argue that there is a need to adopt a standard definition for
                sample quantiles so that the same answers are produced by
                different packages and within each package. We conclude by
                recommending that the median-unbiased estimator be used because
                it has most of the desirable properties of a quantile estimator
                and can be defined independently of the underlying distribution.",
   journal   = "Am. Stat.",
   publisher = "Taylor \& Francis",
   volume    =  50,
   number    =  4,
   pages     = "361--365",
   month     =  nov,
   year      =  1996
 }
 
@Book{knitr,
  title = {Dynamic Documents with {R} and knitr},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2015},
  edition = {2nd},
  url = {https://yihui.name/knitr/},
}

@Book{rmarkdown,
  title = {R Markdown: The Definitive Guide},
  author = {Yihui Xie and J.J. Allaire and Garrett Grolemund},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2018},
  url = {https://bookdown.org/yihui/rmarkdown},
}



@BOOK{Silverman1986-cl,
   title     = "Density estimation for statistics and data analysis",
   author    = "Silverman, B W",
   publisher = "Chapman and Hall",
   series    = "Monographs on statistics and applied probability ; [26]",
   year      =  1986,
   address   = "London ; New York",
   keywords  = "Estimation theory"
 }
 
 

@ARTICLE{Jones1992-pj,
   title    = "Estimating densities, quantiles, quantile densities and density
               quantiles",
   author   = "Jones, M C",
   abstract = "To estimate the quantile density function (the derivative of the
               quantile function) by kernel means, there are two alternative
               approaches. One is the derivative of the kernel quantile
               estimator, the other is essentially the reciprocal of the kernel
               density estimator. We give ways in which the former method has
               certain advantages over the latter. Various closely related
               smoothing issues are also discussed.",
   journal  = "Ann. Inst. Stat. Math.",
   volume   =  44,
   number   =  4,
   pages    = "721--727",
   month    =  dec,
   year     =  1992
 }
  