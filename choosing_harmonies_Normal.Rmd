---
title: Screening harmonies
authors:
- name: Sayani Gupta
  affiliation: Department of Econometrics and Business Statistics, Monash University
  email: Sayani.Gupta@monash.edu

bibliography: bibliography.bib
output:
  bookdown::pdf_book:
    #base_format: rticles::asa_article
    fig_height: 5
    fig_width: 8
    fig_caption: yes
    dev: "pdf"
---

```{r initial, echo = FALSE, cache = FALSE, include = FALSE}
options("knitr.graphics.auto_pdf" = TRUE)
library(knitr)
library(tidyverse)
library(lubridate)
library(lvplot)
library(ggridges)
library(viridis)
library(tsibble)
library(gravitas)
library(ggpubr)
opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE, comment = "#>",
  fig.path = "figure/", fig.align = "center", fig.show = "hold",
  cache = FALSE, cache.path = "cache/",
  out.width = ifelse(is_html_output(), "100%", "\\textwidth")
)
knitr::opts_knit$set(root.dir = here::here())
```

```{r external, include = FALSE}
# read_chunk('scripts/main.R')
```

```{r load}

```

# Idea

Even after excluding clashes, the list of harmonies left could be large and overwhelming for human consumption. Hence, there is a need to rank the  harmonies basis how well they capture the variation in the measured variable and additionally reduce the number of harmonies for further exploration/visualization. Gestalt theory suggests that when items are placed in close proximity, people assume that they are in the same group because they are close to one another and apart from other groups. Hence, displays that capture more variation within different categories in the same group would be important to bring out different patterns of the data. Thus the idea here is to rate a harmony pair higher if this variation between different levels of the x-axis variable is higher on an average across all levels of facet variables.


# Computing distances

One of the potential ways to evaluate this variation is by computing the pairwise distances between the distributions of the measured variable. We do this through Jensen-Shannon divergence which is based on Kullback-Leibler divergence. Probability distributions are represented through sample quantiles instead of kernel density estimate so that there is minimal dependency on selecting kernel or bandwidth.

 We shall call this measure of variation as  Median Maximum Pairwise Distances (MMPD)

# Normalize distances

The harmony pairs could be arranged from highest to lowest average maximum pairwise distances across different levels of the harmonies. But maximum is not robust to the number of levels and is higher for harmonies with higher levels. Thus these maximum pairwise distances need to be normalized for different harmonies in a way that eliminates the effect of different levels. The Fisher–Tippett–Gnedenko theorem in the field of Extreme Value Theory states that the maximum of a sample of iid random variables after proper re- normalization can converge in distribution to only one of Weibull, Gumbel or Freschet distribution, independent of the underlying data or process. The normalizing constants, however, vary depending on the underlying distribution and hence it is important to assume a distribution of distances in our case.

# Choose thresholds for harmonies

| facets/x-axis     	| A_1  	| A_2  	| A_3  	| .. 	| .. 	| A_K  	|
|-----	|------	|------	|------	|----	|----	|------	|
| B_1 	| p_11 	| p_12 	| p_13 	| .. 	| .. 	| p_1K 	|
| B_2 	|      	|      	|      	|    	|    	|      	|
| B_3 	|      	|      	|      	|    	|    	|      	|
| ..  	|      	|      	|      	|    	|    	|      	|
| ..  	|      	|      	|      	|    	|    	|      	|
| B_L 	| p_L1 	| p_L2 	| p_L3 	| .. 	| .. 	| p_LK 	|


$H_{01}: p_{11} = p_{21} = \ldots = p_{L1}$  
$H_{02}: p_{12} = p_{22} = \ldots = p_{L2}$  
\vdots
$H_{0K}: p_{1K} = p_{2K} = \ldots = p_{LK}$  


$m$ = $L \choose 2$ (unordered)  
$m$ = $L-1$ (ordered)  

|  facets/distances	| A_1  	| A_2  	| A_3  	| .. 	| .. 	| A_K  	|
|------------------	|------	|------	|------	|----	|----	|------	|
| d_1              	| d_11 	| d_12 	| d_13 	| .. 	| .. 	| d_1K 	|
| d_2              	|      	|      	|      	|    	|    	|      	|
| d_3              	|      	|      	|      	|    	|    	|      	|
| ..               	|      	|      	|      	|    	|    	|      	|
| ..               	|      	|      	|      	|    	|    	|      	|
| d_m              	| d_m1 	| d_m2 	| d_m3 	| .. 	| .. 	| d_mK 	|

$H_{01}: d_{11} = d_{21} = \ldots = d_{m1} = 0$  
$H_{02}: d_{12} = d_{22} = \ldots = d_{m2} = 0$  
\vdots
$H_{0K}: d_{1K} = d_{2K} = \ldots = d_{mK} = 0$  

 - can do ANOVA at this stage
 - interpretation of results (if interaction of levels significant when testing if means of distributions of distances are equal to zero )

| facets/max-dist 	| A_1       	| A_2       | .. 	| .. 	| A_K       	|
|-----------------	|-----------	|-----------	|-----------	|----	|----	|-----------	|
| max-dist        	| max(d_11, .., dm1) 	| max(d_12, ...d_m2) 	| .. 	| .. 	| max(d_1K,...d_mK) 	|


$H_{01}: max(d_{11}, .., d_{m1}) = 0$  
$H_{02}: max(d_{12}, ...d_{m2})  = 0$  
\vdots
$H_{0K}: max(d_{1K},...d_{mK}) = 0$  

 -  normalised maximum distribution follows standardised Gumbel distribution
 -  multiple hypothesis testing problem where p-values needs to be adjusted with Fisher's combination test (preferred) or Bonferroni's correction
 - What is the test statistic for multiple hypothesis problem?

# Results


##  Smart meter data

normal: standard normal ordered distances  
normal_nonstd: non-standard normal ordered distances  
normal_un: standard normal unordered distances  
normal_nonstd_un: non-standard normal unordered   distances

```{r allgraph}
library(readr)
smart_normal <- read_rds("data/ smart_harmony_normal.rds")  %>% mutate(rank_normal = row_number())

smart_normal_nonstd <- read_rds("data/smart_harmony_nonstd.rds") %>% mutate(rank_normal_nonstnd = row_number())


smart_normal_un <- read_rds("data/smart_harmony_normal_unordered.rds")  %>% mutate(rank_normal_un = row_number())

smart_normal_nonstd_un <- read_rds("data/smart_harmony_nonstd_unordered.rds") %>% mutate(rank_normal_nonstnd_un = row_number())

smart_normal %>% 
  left_join(smart_normal_nonstd, by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
   rename("normal" = "mean_max_variation.x", "normal_nonstd" = "mean_max_variation.y") %>%
  
  left_join(smart_normal_un, by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
  rename("normal_un" = "mean_max_variation") %>%
  
  left_join(smart_normal_nonstd_un, by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>% 
  rename("normal_nonstd_un" = "mean_max_variation")%>% select(-c(normal, normal_nonstd, normal_un, normal_nonstd_un))%>%
  dplyr::rename("normal"  = "rank_normal",
         "normal_nonstd"  = "rank_normal_nonstnd",
         "normal_un"  = "rank_normal_un",
         "normal_nonstd_un"  = "rank_normal_nonstnd_un")%>%   knitr::kable(format = "latex")
```  


<!-- # unordered -->

<!-- ```{r} -->
<!-- library(readr) -->
<!-- smart_normal <- read_rds("data/smart_harmony_normal_unordered.rds")  %>% mutate(rank_normal = row_number()) -->

<!-- smart_normal_nonstd <- read_rds("data/smart_harmony_nonstd_unordered.rds") %>% mutate(rank_normal_nonstnd = row_number()) -->

<!-- smart_normal %>%  -->
<!--   left_join(smart_normal_nonstd, by = c("facet_variable", "x_variable", "facet_levels", "x_levels")) %>%  -->
<!--    rename("normal" = "mean_max_variation.x", "normal_nonstd" = "mean_max_variation.y") %>%  -->
<!--   select(-c(normal, normal_nonstd))%>% -->
<!--   dplyr::rename("normal_unordered"  = "rank_normal", -->
<!--          "normal_nonstd_unordered"  = "rank_normal_nonstnd")%>%   knitr::kable(format = "latex") -->
<!-- ``` -->


## Graphical evidence

```{r, echo = FALSE}
smart_meter10 %>%
  filter(customer_id %in% c(10017936)) %>%
  prob_plot("wknd_wday",
    "hour_day",
    response = "general_supply_kwh",
    plot_type = "boxplot",
    #symmetric = TRUE,
    #quantile_prob = c(0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99)
  ) +
  scale_y_sqrt() +
  #ggtitle(" (b) Area quantile plot faceted by weekend-weekday") +
  ylab("electricity demand [KWh]") + xlab("hours of the day") + ggtitle("") + ylab("")+ 
  theme_minimal() + 
  scale_x_discrete(breaks = seq(0, 23, 5))

smart_meter10 %>%
  filter(customer_id %in% c(10017936)) %>% prob_plot( gran1 = "day_week", gran2 = "day_month", plot_type = "boxplot") + scale_x_discrete(breaks = seq(0, 31, 5))


smart_meter10 %>%
  filter(customer_id %in% c(10017936)) %>% prob_plot(gran1 = "wknd_wday", gran2 = "day_month", plot_type = "boxplot") + scale_x_discrete(breaks = seq(0, 31, 5))


smart_meter10 %>%
  filter(customer_id %in% c(10017936)) %>% 
  prob_plot(gran1 = "wknd_wday", gran2 = "hour_day", plot_type = "boxplot")


smart_meter10 %>%
  filter(customer_id %in% c(10017936)) %>%
  prob_plot("hour_day",
    "wknd_wday",
    response = "general_supply_kwh",
    plot_type = "boxplot",
    #symmetric = TRUE,
    #quantile_prob = c(0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99)
  ) +
  scale_y_sqrt() +
  #ggtitle(" (b) Area quantile plot faceted by weekend-weekday") +
  ylab("electricity demand [KWh]") + xlab("") + ggtitle("") + ylab("")+ 
  theme_minimal() + scale_x_discrete(labels = c('wday','wend'))


```

## cricket data


```{r cricket}
cricket_data <- read_rds("data/cricket_data.rds")

  hierarchy_model <- tibble::tibble(
      units = c("index", "over", "inning", "match"),
      convert_fct = c(1, 20, 2, 1))

hierarchy_tbl <- hierarchy_model

response <- "runs_per_over"

harmonies_cric <- cricket_data %>% harmony(lgran = "over", ugran = "match", filter_in = c("lag_field", "over"), hierarchy_tbl = hierarchy_model)
```


```{r cricket_lag}
cricket_data <- read_rds("data/cricket_data.rds")
cricket_data %>%
  filter(over!=1) %>%
  prob_plot("over", "lag_field",
  hierarchy_model,
  response = "run_rate",
  plot_type = "violin",
  symmetric = FALSE,
 quantile_prob = c(0.25, 0.5, 0.75)) +
   #ggtitle("(b) Runs per over across overs faceted by number of wickets in previous over") +
  ylab("runs per over")  +
  xlab("number of wickets in previous over") +
  ggtitle("b") +
   theme(plot.title = element_text(face = "bold")) +  theme_minimal()
```


# Bibliography

```{r write-bib, eval = FALSE}
write_bib(c("dplyr", "tidyr", "tsibble", "magrittr", "rlang", "gravitas", "knitr", "rmarkdown"), file = "rpkgs.bib")
```
